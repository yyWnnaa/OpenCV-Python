{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "This section runs through the API for common tasks in machine learning. Refer to the links in each section to dive deeper.  \n",
    "\n",
    "### Working with data\n",
    "PyTorch has two primitives to work with data: ``torch.utils.data.DataLoader`` and ``torch.utils.data.Dataset.``   \n",
    "데이터 작업을 위한 두 가지 기본 요소 : torch.utils.data.DataLoader , torch.utils.data.Dataset  \n",
    "\n",
    "`Dataset` stores the samples and their corresponding labels,   \n",
    "샘플과 해당하는 레이블을 저장  \n",
    "\n",
    "and `DataLoader` wraps an iterable around the Dataset.  \n",
    "dataset을 순회하는 기능을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch offers domain-specific libraries such as [TorchText](https://pytorch.org/text/stable/index.html),\n",
    "[TorchVision](https://pytorch.org/vision/stable/index.html), and [TorchAudio](https://pytorch.org/audio/stable/index.html), all of which include datasets.   \n",
    "PyTorch는 TorchText , TorchVision 및 TorchAudio 와 같은 도메인별 라이브러리를 제공하며 모두 데이터 세트를 포함  \n",
    "\n",
    "For this tutorial, we  will be using a TorchVision dataset.  \n",
    "\n",
    "The ``torchvision.datasets`` module contains ``Dataset`` objects for many real-world vision data like CIFAR, COCO ([full list here](https://pytorch.org/vision/stable/datasets.html)).   \n",
    "torchvision.datasets모듈에는 CIFAR, COCO와 같은 많은 실제 비전 데이터에 대한 개체가 포함되어 있음  \n",
    "\n",
    "In this tutorial, we use the FashionMNIST dataset.   \n",
    "\n",
    "Every TorchVision ``Dataset`` includes two arguments: ``transform`` and\n",
    "``target_transform`` to modify the samples and labels respectively.  \n",
    "모든 TorchVision에는 샘플과 라벨을 각각 수정하는 두 가지 인수가 포함되어 있음 : Dataset transform, target_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(), # 데이터를 텐서로 저장\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the ``Dataset`` as an argument to ``DataLoader``.   \n",
    "Dataset을 DataLoader의 인자로 전달  \n",
    "\n",
    "This wraps an iterable over our dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading.   \n",
    "이는 데이터셋에 대한 반복 가능한(iterable) 객체를 래핑하며, 자동으로 배치 처리, 샘플링, 셔플링 및 다중 프로세스 데이터 로딩을 지원  \n",
    "\n",
    "Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\n",
    "데이터로더(iterable)의 각 요소는 64개의 피처와 레이블로 구성된 배치를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Models\n",
    "To define a neural network in PyTorch, we create a class that inherits from ``nn.Module``.  \n",
    "PyTorch에서 신경망을 정의하려면 nn.Module에서 상속받은 클래스를 생성  \n",
    "\n",
    "We define the layers of the network in the ``__init__`` function and specify how data will pass through the network in the forward function.   \n",
    "함수에서 네트워크의 계층을 정의 __init__하고  \n",
    "함수에서 데이터가 네트워크를 통과하는 방법을 지정 (forward)  \n",
    "\n",
    "To accelerate operations in the neural network, we move it to the GPU or MPS if available. \n",
    "신경망의 연산을 가속화하기 위해 가능한 경우 GPU 또는 MPS로 이동  \n",
    "\n",
    "MPS : Apple M1 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module): # nn.Module 클래스를 상속 # NeuralNetwork이 자식클래스\n",
    "    def __init__(self): # 뉴럴 네트워크의 성분을 정의\n",
    "        super().__init__() # 부모 클래스의 초기화 함수를 호출해서 속성을 초기화, 필요한 기능 추가\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the Model Parameters\n",
    "To train a model, we need a loss function and an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches),   \n",
    "and backpropagates the prediction error to adjust the model’s parameters.  \n",
    "단일 훈련 루프에서 모델은 훈련 데이터세트(일괄적으로 입력)에 대해 예측을 수행하고 예측 오류를 역전파하여 모델의 매개변수를 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y) # loss_fn = nn.CrossEntropyLoss() 지정했음\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 최적화 함수를 사용하여 모델의 매개변수 업데이트\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check the model’s performance against the test dataset to ensure it is learning.  \n",
    "또한 테스트 데이터 세트와 비교하여 모델 성능을 확인하여 학습 중인지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process is conducted over several iterations (epochs).   \n",
    "훈련 과정은 여러 반복(epoch)에 걸쳐 수행  \n",
    "\n",
    "During each epoch, the model learns parameters to make better predictions.   \n",
    "각 epoch마다 모델은 더 나은 예측을 위해 매개변수를 학습  \n",
    "에포크를 세대라고 번역하기도 함 (책에서도 세대라는 용어 나왔음)\n",
    "\n",
    "We print the model’s accuracy and loss at each epoch;   \n",
    "각 epoch마다 모델의 정확도와 손실을 인쇄  \n",
    "\n",
    "we’d like to see the accuracy increase and the loss decrease with every epoch.  \n",
    "매 에포크마다 정확도가 증가하고 손실이 감소하는 것을 예상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302471  [   64/60000]\n",
      "loss: 2.287063  [ 6464/60000]\n",
      "loss: 2.271568  [12864/60000]\n",
      "loss: 2.265818  [19264/60000]\n",
      "loss: 2.237872  [25664/60000]\n",
      "loss: 2.219079  [32064/60000]\n",
      "loss: 2.229588  [38464/60000]\n",
      "loss: 2.188260  [44864/60000]\n",
      "loss: 2.185202  [51264/60000]\n",
      "loss: 2.164438  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.1%, Avg loss: 2.146684 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.156263  [   64/60000]\n",
      "loss: 2.142411  [ 6464/60000]\n",
      "loss: 2.081804  [12864/60000]\n",
      "loss: 2.099488  [19264/60000]\n",
      "loss: 2.039707  [25664/60000]\n",
      "loss: 1.988637  [32064/60000]\n",
      "loss: 2.025023  [38464/60000]\n",
      "loss: 1.930287  [44864/60000]\n",
      "loss: 1.942073  [51264/60000]\n",
      "loss: 1.880179  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 1.863148 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.899779  [   64/60000]\n",
      "loss: 1.867910  [ 6464/60000]\n",
      "loss: 1.740246  [12864/60000]\n",
      "loss: 1.785234  [19264/60000]\n",
      "loss: 1.672924  [25664/60000]\n",
      "loss: 1.635085  [32064/60000]\n",
      "loss: 1.663779  [38464/60000]\n",
      "loss: 1.551665  [44864/60000]\n",
      "loss: 1.589993  [51264/60000]\n",
      "loss: 1.491705  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.3%, Avg loss: 1.499269 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.571530  [   64/60000]\n",
      "loss: 1.538535  [ 6464/60000]\n",
      "loss: 1.379980  [12864/60000]\n",
      "loss: 1.454274  [19264/60000]\n",
      "loss: 1.336691  [25664/60000]\n",
      "loss: 1.338003  [32064/60000]\n",
      "loss: 1.354473  [38464/60000]\n",
      "loss: 1.271258  [44864/60000]\n",
      "loss: 1.319110  [51264/60000]\n",
      "loss: 1.221907  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.244621 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.324696  [   64/60000]\n",
      "loss: 1.308843  [ 6464/60000]\n",
      "loss: 1.137239  [12864/60000]\n",
      "loss: 1.242280  [19264/60000]\n",
      "loss: 1.119618  [25664/60000]\n",
      "loss: 1.146191  [32064/60000]\n",
      "loss: 1.165862  [38464/60000]\n",
      "loss: 1.098886  [44864/60000]\n",
      "loss: 1.149882  [51264/60000]\n",
      "loss: 1.066332  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.086290 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Models\n",
    "A common way to save a model is to serialize the internal state dictionary (containing the model parameters).  \n",
    "모델을 저장하는 일반적인 방법은 내부 상태 사전(모델 매개변수 포함)을 직렬화하는 것  \n",
    "internal state dictionary 내부 상태 사전으로 번역됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models\n",
    "The process for loading a model includes re-creating the model structure and loading the state dictionary into it.  \n",
    "모델을 로드하는 프로세스에는 모델 구조를 다시 만들고 상태 사전을 해당 구조에 로드하는 작업이 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\")) # 이후 모델을 업데이트하려면 모델에 대한 정보가 있어야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can now be used to make predictions.  \n",
    "이제 이 모델을 사용하여 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
